{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cbed6f4-6833-4a96-bf9c-e201c3917f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import neuropythy as ny\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import curve_fit\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a521cbcf-2537-4eb7-8214-2d1fb67c3634",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings\n",
    "max_ecc = 8\n",
    "max_CM = 50\n",
    "r2_th = 0.1\n",
    "rois = [\"V1\", \"V2\", \"V3\", \"hV4\", \"VO1\", \"VO2\",\n",
    "        \"PHC1\", \"PHC2\", \"TO2\", \"TO1\", \"LO2\", \"LO1\", \"V3B\", \"V3A\",\n",
    "        \"IPS0\", \"IPS1\", \"IPS2\", \"IPS3\", \"IPS4\", \"IPS5\", \"SPL1\", \"FEF\"]\n",
    "# Define ROI groups\n",
    "# roi_groups = {\n",
    "#     \"Early visual areas\": [\"V1v\",\"V1d\",\"V2v\",\"V2d\",\"V3v\",\"V3d\"],\n",
    "#     \"Intermediate visual areas\": [\"V3A\",\"V3B\",\"hV4\",\"LO1\",\"LO2\",\"VO1\",\"VO2\"],\n",
    "#     \"Higher-level visual areas\": [\"TO1\",\"TO2\",\"PHC1\",\"PHC2\",\"IPS0\",\"IPS1\",\"IPS2\",\"IPS3\",\"IPS4\",\"IPS5\",\"SPL1\",\"hFEF\"],\n",
    "# }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42bee6f9-c8fd-4361-9368-57846a3e30c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get subject numbers\n",
    "allsub = ny.data['hcp_lines'].subject_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002c73e6-a69f-4252-8546-fe3f77dd9a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/naxos2-raid27/wong0876/pRF_project/tsv/group_tsv'\n",
    "grouptsv = pd.read_csv('{}/dist_concat_r2_filtered.tsv'.format(path), sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044db3d6-7db3-4950-96b6-5583741812e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group ventral and dorsal for V1, V2, V3\n",
    "roi_map = {\n",
    "    \"V1v\": \"V1\", \"V1d\": \"V1\",\n",
    "    \"V2v\": \"V2\", \"V2d\": \"V2\",\n",
    "    \"V3v\": \"V3\", \"V3d\": \"V3\",\n",
    "}\n",
    "\n",
    "# Replace labels in grouptsv\n",
    "grouptsv['roi'] = grouptsv['roi'].replace(roi_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec933205-0583-4e83-b0b2-d1b88d2fed9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.optimize import least_squares, minimize_scalar\n",
    "from scipy.stats import chi2\n",
    "\n",
    "# === New Harvey functions on log scale ===\n",
    "def harvey_func(x, c, d):\n",
    "    # original scale\n",
    "    return 1.0 / (c*x + d)\n",
    "\n",
    "def harvey_log_func(x, c, d):\n",
    "    # log-scale model: log(y) = -2 * log(c*x + d)\n",
    "    return -np.log(c*x + d)\n",
    "\n",
    "# === Horton function ===\n",
    "def horton_func(x):\n",
    "    return 17.3 / (x + 0.75)\n",
    "\n",
    "# === Residuals on log scale ===\n",
    "def residuals_log(params, x, y):\n",
    "    c, d = params\n",
    "    return np.log(y) - harvey_log_func(x, c, d)\n",
    "\n",
    "# === Fit on log scale with bounds for stability ===\n",
    "def fit_harvey_log(x, y):\n",
    "    # ensure positivity\n",
    "    if np.any(y <= 0):\n",
    "        raise ValueError(\"y must be positive for log transform\")\n",
    "\n",
    "    p0 = [0.01, 1.0]\n",
    "    # bounds keep c,d reasonable\n",
    "    res = least_squares(residuals_log, p0, args=(x, y),\n",
    "                        loss='huber', f_scale=0.05,\n",
    "                        bounds=([1e-6, 0.01], [1.0, 20.0]))\n",
    "    c_hat, d_hat = res.x\n",
    "    # residuals in log-domain\n",
    "    fun = res.fun\n",
    "    sigma2_hat = np.var(fun, ddof=2)  # variance of log-residuals\n",
    "    # Jacobian of log-residuals at data points (rows: n_data, cols: params)\n",
    "    # For log model r = log(y) - (-2 log(c x + d)) = log(y) + 2 log(c x + d)\n",
    "    # So derivative of model m = -2 log(c x + d) => dm/dc = -2 * x / (c x + d), dm/dd = -2 * 1 / (c x + d)\n",
    "    J = np.column_stack([\n",
    "        -2.0 * x / (c_hat * x + d_hat),   # dm/dc  (note: derivative of m wrt c)\n",
    "        -2.0 / (c_hat * x + d_hat)        # dm/dd\n",
    "    ])\n",
    "    # Covariance of parameters (approx): cov = (J^T J)^{-1} * sigma2\n",
    "    try:\n",
    "        cov_params = np.linalg.inv(J.T @ J) * sigma2_hat\n",
    "    except np.linalg.LinAlgError:\n",
    "        cov_params = np.diag([1e-6, 1e-6])\n",
    "    return (c_hat, d_hat), cov_params, sigma2_hat, res.fun\n",
    "\n",
    "# === Asymptotic CI computed in log-space and exponentiated ===\n",
    "def asymptotic_ci_log(x_common, x_data, y_data, best_params, cov_params, sigma2_hat, alpha=0.05):\n",
    "    c_hat, d_hat = best_params\n",
    "    # predicted log y\n",
    "    logy_fit = harvey_log_func(x_common, c_hat, d_hat)\n",
    "\n",
    "    # derivatives of logy wrt params at prediction points\n",
    "    dlogy_dc = -2.0 * x_common / (c_hat * x_common + d_hat)\n",
    "    dlogy_dd = -2.0 / (c_hat * x_common + d_hat)\n",
    "    J_pred = np.column_stack([dlogy_dc, dlogy_dd])\n",
    "\n",
    "    # variance of log-prediction: var_logy = J_pred @ cov_params @ J_pred^T\n",
    "    # compute vectorized:\n",
    "    var_logy = np.einsum('ij,jk,ik->i', J_pred, cov_params, J_pred)\n",
    "\n",
    "    # add observation noise if you want prediction intervals (optional)\n",
    "    # var_pred_log = var_logy + sigma2_hat   # uncomment for prediction interval\n",
    "    var_pred_log = var_logy\n",
    "\n",
    "    se_log = np.sqrt(np.maximum(var_pred_log, 0.0))\n",
    "    z = 1.96  # ~95% CI\n",
    "    log_lower = logy_fit - z * se_log\n",
    "    log_upper = logy_fit + z * se_log\n",
    "\n",
    "    # exponentiate to get CI on original scale\n",
    "    y_fit = np.exp(logy_fit)\n",
    "    y_lower = np.exp(log_lower)\n",
    "    y_upper = np.exp(log_upper)\n",
    "\n",
    "    return y_fit, y_lower, y_upper\n",
    "\n",
    "# -----------------------------\n",
    "# RMSE\n",
    "# -----------------------------\n",
    "def compute_rmse(y_true, y_pred):\n",
    "    return np.sqrt(np.mean((y_true - y_pred)**2))\n",
    "\n",
    "# -----------------------------\n",
    "# ROI order\n",
    "# -----------------------------\n",
    "rois = [\"V1\", \"V2\", \"V3\", \"hV4\", \"VO1\", \"VO2\",\n",
    "        \"PHC1\", \"PHC2\", \"TO2\", \"TO1\", \"LO2\", \"LO1\", \"V3B\", \"V3A\",\n",
    "        \"IPS0\", \"IPS1\", \"IPS2\", \"IPS3\", \"IPS4\", \"IPS5\", \"SPL1\", \"FEF\"]\n",
    "\n",
    "# -----------------------------\n",
    "# Run across ROIs\n",
    "# -----------------------------\n",
    "x_common = np.linspace(0, 8, 200)\n",
    "roi_results = {}\n",
    "roi_metrics = {}\n",
    "\n",
    "for roi in rois:\n",
    "    print(roi, end=' ')\n",
    "    df_roi = grouptsv[grouptsv['roi'] == roi]\n",
    "    if len(df_roi) < 5:\n",
    "        continue\n",
    "\n",
    "    x = df_roi['prf_ecc'].to_numpy()\n",
    "    y = df_roi['pRF_CM'].to_numpy()\n",
    "\n",
    "    # Fit Harvey\n",
    "    # fit on log scale\n",
    "    best_params, cov_params, sigma2_hat, fun = fit_harvey_log(x, y)\n",
    "    c_hat, d_hat = best_params\n",
    "\n",
    "    # compute asymptotic CI in log space (smooth, multiplicative bands)\n",
    "    y_fixed, y_lower, y_upper = asymptotic_ci_log(x_common, x, y, best_params, cov_params, sigma2_hat, alpha=0.05)\n",
    "\n",
    "    # Save results\n",
    "    roi_results[roi] = {\n",
    "        \"x_common\": x_common,\n",
    "        \"y_fixed\": y_fixed,\n",
    "        \"y_lower\": y_lower,\n",
    "        \"y_upper\": y_upper,\n",
    "        \"params\": {\"c\": c_hat, \"d\": d_hat},\n",
    "        \"y_horton\": horton_func(x_common)\n",
    "    }\n",
    "\n",
    "    # RMSE\n",
    "    y_pred = harvey_func(x, c_hat, d_hat)\n",
    "    roi_metrics[roi] = {\"Harvey_RMSE\": compute_rmse(y, y_pred)}\n",
    "\n",
    "# -----------------------------\n",
    "# Print summary\n",
    "# -----------------------------\n",
    "for roi in rois:\n",
    "    if roi in roi_metrics:\n",
    "        print(f\"{roi}: Harvey RMSE={roi_metrics[roi]['Harvey_RMSE']:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5587d2f5-079c-424f-bbc9-2b99c1e6a738",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('roi_results_dist.npy', roi_results)\n",
    "np.save('roi_metrics_dist.npy', roi_metrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 (local)",
   "language": "python",
   "name": "localenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
